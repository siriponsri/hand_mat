# ğŸ“‹ à¸„à¸¹à¹ˆà¸¡à¸·à¸­à¸à¸²à¸£à¸§à¸²à¸‡ Models à¸ªà¸³à¸«à¸£à¸±à¸š HandMat

## ğŸ—‚ï¸ à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œà¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¹‰à¸§

```
handmat/
â”œâ”€â”€ backend/models/
â”‚   â”œâ”€â”€ hand/           âœ… à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¹‰à¸§ - à¸§à¸²à¸‡ Teachable Machine models
â”‚   â”œâ”€â”€ face/           âœ… à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¹‰à¸§ - à¸ªà¸³à¸£à¸­à¸‡ (à¹„à¸¡à¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™)
â”‚   â””â”€â”€ llm/            âœ… à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¹‰à¸§ - à¸ªà¸³à¸«à¸£à¸±à¸š Local LLM (optional)
â””â”€â”€ frontend/public/models/  âœ… à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¹‰à¸§ - à¸§à¸²à¸‡ face-api.js models
```

## ğŸ¤– 1. Hand Model (Teachable Machine)

### à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸§à¸²à¸‡:
```
backend/models/hand/
â”œâ”€â”€ model.tflite      ğŸ‘ˆ à¸§à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¸™à¸µà¹‰
â””â”€â”€ metadata.json     ğŸ‘ˆ à¸§à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¸™à¸µà¹‰
```

### à¸§à¸´à¸˜à¸µà¸à¸²à¸£:
1. **Train Model** à¸—à¸µà¹ˆ https://teachablemachine.withgoogle.com/
   - à¹€à¸¥à¸·à¸­à¸ "Image Project"
   - à¸­à¸±à¸à¹‚à¸«à¸¥à¸”à¸£à¸¹à¸›à¸—à¹ˆà¸²à¸—à¸²à¸‡à¸¡à¸·à¸­à¸•à¹ˆà¸²à¸‡à¹†
   - Train à¸ˆà¸™à¹„à¸”à¹‰à¸œà¸¥à¸—à¸µà¹ˆà¸à¸­à¹ƒà¸ˆ

2. **Export Model**
   - à¸„à¸¥à¸´à¸ "Export Model"
   - à¹€à¸¥à¸·à¸­à¸ "TensorFlow Lite"
   - Download à¹„à¸Ÿà¸¥à¹Œ `model.tflite` à¹à¸¥à¸° `metadata.json`

3. **à¸§à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ**
   ```bash
   # Copy à¹„à¸Ÿà¸¥à¹Œà¹„à¸›à¸¢à¸±à¸‡
   backend/models/hand/model.tflite
   backend/models/hand/metadata.json
   ```

### à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ metadata.json:
```json
{
  "labels": ["hello", "thank_you", "goodbye", "yes", "no"],
  "preprocessing": {
    "mean": 127.5,
    "std": 127.5
  }
}
```

## ğŸ‘¥ 2. Face Model (face-api.js)

### à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸§à¸²à¸‡:
```
frontend/public/models/
â”œâ”€â”€ tiny_face_detector_model-weights_manifest.json
â”œâ”€â”€ tiny_face_detector_model-shard1
â”œâ”€â”€ face_expression_model-weights_manifest.json
â”œâ”€â”€ face_expression_model-shard1
â””â”€â”€ face_expression_model-shard2
```

### à¸§à¸´à¸˜à¸µà¸à¸²à¸£:
1. **Download Models** à¸ˆà¸²à¸ GitHub:
   ```bash
   # à¹„à¸›à¸—à¸µà¹ˆ
   https://github.com/justadudewhohacks/face-api.js/tree/master/weights
   
   # Download à¹„à¸Ÿà¸¥à¹Œà¹€à¸«à¸¥à¹ˆà¸²à¸™à¸µà¹‰:
   - tiny_face_detector_model-weights_manifest.json
   - tiny_face_detector_model-shard1
   - face_expression_model-weights_manifest.json  
   - face_expression_model-shard1
   - face_expression_model-shard2
   ```

2. **à¸§à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸™ frontend/public/models/**

### Alternative: à¹ƒà¸Šà¹‰ CDN
```typescript
// à¹ƒà¸™ frontend code à¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸Šà¹‰ CDN à¹à¸—à¸™
await faceapi.nets.tinyFaceDetector.loadFromUri(
  'https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights'
);
```

## ğŸ§  3. LLM Integration

### Option 1: API Service (à¹à¸™à¸°à¸™à¸³)
```typescript
// à¹ƒà¸™ backend/api/compose.py
// à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™à¹ƒà¸Šà¹‰ mock LLM
// à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸Šà¸·à¹ˆà¸­à¸¡ API:

// OpenAI GPT
const response = await openai.chat.completions.create({
  model: "gpt-3.5-turbo",
  messages: [{"role": "user", "content": prompt}]
});

// Google Gemini  
const result = await model.generateContent(prompt);

// Local API
const response = await fetch('http://localhost:11434/api/generate', {
  method: 'POST',
  body: JSON.stringify({ model: 'llama2', prompt: prompt })
});
```

### Option 2: Local LLM (à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡)
```
backend/models/llm/
â”œâ”€â”€ model.bin         # Ollama, LM Studio model
â”œâ”€â”€ config.json       # Model configuration
â””â”€â”€ tokenizer.json    # Tokenizer settings
```

## ğŸš€ à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š Models

### 1. à¸—à¸”à¸ªà¸­à¸š Hand Model
```bash
# Start backend
cd backend
python app.py

# Test API
curl -X POST http://localhost:5000/api/recognize \
  -H "Content-Type: application/json" \
  -d '{"image": "base64_image_data"}'
```

### 2. à¸—à¸”à¸ªà¸­à¸š Face Model
```javascript
// à¹ƒà¸™ frontend
const detection = await faceapi
  .detectSingleFace(imageElement)
  .withFaceExpressions();
```

### 3. à¸—à¸”à¸ªà¸­à¸š LLM
```bash
curl -X POST http://localhost:5000/api/compose \
  -H "Content-Type: application/json" \
  -d '{
    "hand_recognition": {"prediction": "hello", "confidence": 0.9},
    "face_emotion": {"emotion": "happy", "confidence": 0.8}
  }'
```

## ğŸ“ à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š

### Hand Model Status:
```bash
# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹„à¸Ÿà¸¥à¹Œà¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸—à¸µà¹ˆà¸–à¸¹à¸
ls backend/models/hand/
# à¸„à¸§à¸£à¹€à¸«à¹‡à¸™: model.tflite, metadata.json
```

### Face Model Status:
```bash
# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š face-api.js models
ls frontend/public/models/
# à¸„à¸§à¸£à¹€à¸«à¹‡à¸™: tiny_face_detector_*, face_expression_*
```

### Backend API Status:
```bash
curl http://localhost:5000/api/health
# à¸„à¸§à¸£à¹„à¸”à¹‰ response à¸à¸£à¹‰à¸­à¸¡ model status
```

## ğŸ”§ Troubleshooting

### à¸–à¹‰à¸² Hand Model à¹„à¸¡à¹ˆà¹‚à¸«à¸¥à¸”:
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š path: `backend/models/hand/model.tflite`
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š `metadata.json` format
- Install TensorFlow: `pip install tensorflow`

### à¸–à¹‰à¸² Face Model à¹„à¸¡à¹ˆà¹‚à¸«à¸¥à¸”:
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š path: `frontend/public/models/`
- à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰ CDN à¹à¸—à¸™ local files
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š network à¹ƒà¸™ browser dev tools

### à¸–à¹‰à¸² LLM à¹„à¸¡à¹ˆà¸—à¸³à¸‡à¸²à¸™:
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š API keys (OpenAI, Google)
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Local LLM server status
- à¸”à¸¹ logs à¹ƒà¸™ backend console

## âœ… Next Steps

1. **à¸§à¸²à¸‡ Hand Model** à¸ˆà¸²à¸ Teachable Machine
2. **à¸§à¸²à¸‡ Face Models** à¸ˆà¸²à¸ face-api.js  
3. **Configure LLM** (API à¸«à¸£à¸·à¸­ Local)
4. **à¸—à¸”à¸ªà¸­à¸š Complete Flow** à¸—à¸±à¹‰à¸‡à¸£à¸°à¸šà¸š

à¸£à¸°à¸šà¸šà¸ˆà¸°à¸—à¸³à¸‡à¸²à¸™à¹„à¸”à¹‰à¸„à¸£à¸šà¸–à¹‰à¸§à¸™à¹€à¸¡à¸·à¹ˆà¸­à¸¡à¸µ models à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹à¸¥à¹‰à¸§! ğŸ¯
